{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","include_colab_link":true,"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8432200,"sourceType":"datasetVersion","datasetId":5021864},{"sourceId":8571023,"sourceType":"datasetVersion","datasetId":5124944}],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Riky2014/NAPDE/blob/main/cervelli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"colab_type":"text","id":"view-in-github"}},{"cell_type":"markdown","source":"# Install MONAI","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install -U \"monai-weekly[fire, nibabel, yaml, tqdm, einops]\"","metadata":{"id":"sHT26yHPqbA6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport tempfile\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\n\nimport monai\nfrom monai.losses import DiceLoss\nfrom monai.metrics import DiceMetric\nfrom monai.config import print_config\nfrom monai.utils import set_determinism\nfrom monai.networks.nets import SegResNet\nfrom monai.inferers import sliding_window_inference\nfrom monai.data import DataLoader, decollate_batch\n\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()\n\nfrom monai.transforms import (\n    Activations,\n    AsDiscrete,\n    Compose,\n    LoadImaged,\n    NormalizeIntensityd,\n    Orientationd,\n    RandFlipd,\n    RandScaleIntensityd,\n    RandShiftIntensityd,\n    RandSpatialCropd,\n    Spacingd,\n    EnsureTyped,\n    EnsureChannelFirstd,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Print configuration\nThis instruction is not mandatory: it just shows the details regarding the current work configuration.","metadata":{}},{"cell_type":"code","source":"print_config()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set the directory\nHere we set the working directory.","metadata":{}},{"cell_type":"code","source":"directory_path = '/kaggle/working/cervelli'\nos.makedirs(directory_path, exist_ok = True)\nos.environ[\"MONAI_DATA_DIRECTORY\"] = directory_path\ndirectory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\nroot_dir = tempfile.mkdtemp() if directory is None else directory","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwiaTFdKEFSx","outputId":"cae23b40-ec22-4e0d-fb31-dc3255752f03","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Auxiliary functions\nFirst of all, it is necessary to execute all the cells belonging to this section.","metadata":{"id":"ZG6arPrlhZFl"}},{"cell_type":"code","source":"def create_dataset(n_train, n_test):\n  os.environ[\"MONAI_DATA_DIRECTORY\"] = \"/kaggle/input/ciaooo/Immagini_cervelli_giuste\" #this directory need to be changed according to the location of the dataset\n  directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n  root_dir = tempfile.mkdtemp() if directory is None else directory\n\n  set_determinism(seed = 0)\n\n  images = sorted(glob(os.path.join(root_dir, \"image*.nii\")))\n  labels = sorted(glob(os.path.join(root_dir, \"label*.nii\")))\n\n  train_files = [{\"image\": image, \"label\": label} for image,\n                 label in zip(images[:n_train], labels[:n_train])]\n  val_files = [{\"image\": image, \"label\": label} for image,\n               label in zip(images[-n_test:], labels[-n_test:])]\n\n  return train_files, val_files","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform(train_files, val_files):\n  train_transform = Compose([\n      LoadImaged(keys=[\"image\", \"label\"]),\n      EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n      EnsureTyped(keys=[\"image\", \"label\"]),\n      Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n      Spacingd(\n          keys=[\"image\", \"label\"],\n          pixdim=(1.0, 1.0, 1.0),\n          mode=(\"bilinear\", \"nearest\"),\n      ),\n      RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[240, 240, 160], random_size=False),\n      RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n      RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n      RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n      NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n      RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n      RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n  ])\n\n  val_transform = Compose([\n      LoadImaged(keys=[\"image\", \"label\"]),\n      EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n      EnsureTyped(keys=[\"image\", \"label\"]),\n      Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n      Spacingd(\n          keys=[\"image\", \"label\"],\n          pixdim=(1.0, 1.0, 1.0),\n          mode=(\"bilinear\", \"nearest\"),\n      ),\n      NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n  ])\n\n  train_ds = monai.data.Dataset(data=train_files, transform=train_transform)\n  train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=2)\n\n  val_ds = monai.data.Dataset(data=val_files, transform=val_transform)\n  val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=2)\n\n  return train_loader, val_loader, val_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference(input, model, VAL_AMP):\n    def _compute(input):\n        return sliding_window_inference(\n            inputs=input,\n            roi_size=(240, 240, 160),\n            sw_batch_size=1,\n            predictor=model,\n            overlap=0.5,\n        )\n\n    if VAL_AMP:\n        with torch.cuda.amp.autocast():\n            return _compute(input)\n    else:\n        return _compute(input)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_and_train(n_train, n_test, train_loader, val_loader, max_epochs, val_ds, filters = 16):\n  print(f\"Start training\")\n  print(f\"Number of training images = {n_train}\")\n  print(f\"Number of testing images = {n_test}\")\n  print()\n    \n  val_interval = 1\n  VAL_AMP = True\n\n  device = torch.device(\"cuda:0\")\n  model = SegResNet(\n    blocks_down=[1, 2, 2, 4], #default: [1, 2, 2, 4]\n    blocks_up=[1, 1, 1], #default: [1, 1, 1]\n    init_filters=filters,\n    in_channels=1,\n    out_channels=1,\n    dropout_prob=0.2,\n  ).to(device)\n\n  loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True,\n                           to_onehot_y=False, sigmoid=True)\n  optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n  lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n\n  dice_metric = DiceMetric(include_background=False, reduction=\"mean\")        # False\n  dice_metric_train = DiceMetric(include_background=False, reduction=\"mean\")  # False\n\n  post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n\n  scaler = torch.cuda.amp.GradScaler()\n  torch.backends.cudnn.benchmark = True\n\n  epoch_loss_values = []\n  metric_values = []\n  metric_values_train = []\n\n  total_start = time.time()\n    \n  for epoch in range(max_epochs):\n    epoch_start = time.time()\n    print(\"-\" * 10)\n    print(f\"epoch {epoch + 1}/{max_epochs}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step_start = time.time()\n        step += 1\n        inputs, labels = (\n            batch_data[\"image\"].to(device),\n            batch_data[\"label\"].to(device)\n        )\n        optimizer.zero_grad()\n\n        with torch.cuda.amp.autocast():\n            outputs = model(inputs)  #inference\n            loss = loss_function(outputs, labels)\n\n        outputs = [post_trans(i) for i in decollate_batch(outputs)]  # added by the guy\n\n        dice_metric_train(y_pred=outputs, y=labels)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        epoch_loss += loss.item()\n        \n\n    metric_train = dice_metric_train.aggregate().item()\n    metric_values_train.append(metric_train)\n    dice_metric_train.reset()\n\n    lr_scheduler.step()\n    epoch_loss /= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"Loss: {epoch_loss:.4f} \\nTrain dice: {metric_train:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            for val_data in val_loader:\n                val_inputs, val_labels = (\n                    val_data[\"image\"].to(device),\n                    val_data[\"label\"].to(device)\n                )\n                val_outputs = inference(val_inputs, model, VAL_AMP)  #model\n                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n\n                dice_metric(y_pred=val_outputs, y=val_labels)\n\n            metric = dice_metric.aggregate().item()\n            metric_values.append(metric)\n            dice_metric.reset()\n            print(f\"Test dice: {metric:.4f}\")\n\n    print(f\"Time: {(time.time() - epoch_start):.4f}\")\n    \n  total_time = time.time() - total_start\n  print(f\"Train completed, total time: {total_time}.\")\n  print()\n  print(f\"Train metric = {metric_values_train[-1]}, Test metric = {metric_values[-1]}\")\n  print()\n  print()\n\n  return metric_values_train, metric_values, epoch_loss_values, model, device, VAL_AMP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_patient(plot_index, z_coordinate, val_ds):\n  val_data_example = val_ds[plot_index]\n  plt.figure(\"patient\", (12, 6))\n\n  #plot of the input image\n  print(f\"image shape: {val_data_example['image'].shape}\")\n  plt.subplot(1, 2, 1)\n  plt.title(f\"patient {plot_index}, input image\")\n  plt.imshow(val_data_example[\"image\"][0,:, :,z_coordinate].detach().cpu(), cmap=\"gray\")\n\n  # also visualize the label corresponding to this image\n  print(f\"label shape: {val_data_example['label'].shape}\")\n  plt.subplot(1, 2, 2)\n  plt.title(f\"patient {plot_index}, label\")\n  plt.imshow(val_data_example[\"label\"][0,:, :,z_coordinate].detach().cpu())\n    \n  plt.show()\n    \n  return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(epoch_loss_values, metric_values, metric_values_train, val_interval, n_train, max_epochs):\n  output_dir = '/kaggle/working/output_plots'\n  os.makedirs(output_dir, exist_ok=True)\n  plot_path = os.path.join(output_dir,\n                           f\"loss and metrics, n_train = {n_train}, epochs = {max_epochs}.png\")\n\n  plt.figure(\"train\", (18, 6))\n\n  # Loss function\n  plt.subplot(1, 3, 1)\n  plt.title(\"Loss\")\n  x = [i + 1 for i in range(len(epoch_loss_values))]\n  y = epoch_loss_values\n  plt.xlabel(\"epoch\")\n  plt.plot(x, y, color=\"red\")\n\n  # Test metric\n  plt.subplot(1, 3, 2)\n  plt.title(\"Test metric\")\n  x = [val_interval * (i + 1) for i in range(len(metric_values))]\n  y = metric_values\n  plt.xlabel(\"epoch\")\n  plt.plot(x, y, color=\"green\")\n\n  # Train metric\n  plt.subplot(1, 3, 3)\n  plt.title(\"Train metric\")\n  x = [val_interval * (i + 1) for i in range(len(metric_values_train))]\n  y = metric_values_train\n  plt.xlabel(\"epoch\")\n  plt.plot(x, y, color=\"blue\")\n\n  plt.savefig(plot_path)\n  plt.show()\n  \n  return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_test_slices(model, val_ds, VAL_AMP, patient_indices, z_axis_values):\n  post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n      \n  with torch.no_grad():\n    for k in range(len(patient_indices)):\n      # choose \"i\", index of the testing image to be plotted,\n      # and \"j\", value of the z-axis corresponding to the\n      # x-y section to be plotted\n      i = patient_indices[k]\n      j = z_axis_values[k]\n\n      # select one image to evaluate and visualize the model output\n      val_input = val_ds[i][\"image\"].unsqueeze(0).to(device)\n      roi_size = (128, 128, 64)  #(240, 240, 160)\n      sw_batch_size = 4\n      val_output = inference(val_input, model, VAL_AMP)\n      val_output = post_trans(val_output[0])\n        \n      plt.figure(\"current patient\", (18, 6))\n      \n      #plot of the input image\n      plt.subplot(1, 3, 1)\n      plt.title(f\"input image, patient {i}, z = {j}\")\n      plt.imshow(val_ds[i][\"image\"][0, :, :, j].detach().cpu(), cmap=\"gray\")\n        \n      #plot of the label\n      plt.subplot(1, 3, 2)\n      plt.title(f\"label, patient {i}, z = {j}\")\n      plt.imshow(val_ds[i][\"label\"][0, :, :, j].detach().cpu())\n        \n      #plot of the output\n      plt.subplot(1, 3, 3)\n      plt.title(f\"output, patient {i}, z = {j}\")\n      plt.imshow(val_output[0, :, :, j].detach().cpu())\n        \n      plt.show()\n  return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_test_3d(VAL_AMP, device, model, val_ds, n_train, max_epochs):\n  post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n  number_val_patients = len(val_ds)\n    \n  output_dir = '/kaggle/working/test_3d_plots'\n  os.makedirs(output_dir, exist_ok=True)\n\n  with torch.no_grad():\n    for i in range(number_val_patients):\n      val_input = val_ds[i][\"image\"].unsqueeze(0).to(device)\n      roi_size = (128, 128, 64)  #(240, 240, 160)\n      sw_batch_size = 4\n      val_output = inference(val_input, model, VAL_AMP)\n      val_output = post_trans(val_output[0])\n    \n      # create figure with three subplots for display\n      fig = plt.figure(figsize=(18, 6))\n  \n      # 3d plot of the input image\n      ax = fig.add_subplot(131, projection = '3d')\n      z, x, y = val_ds[i][\"image\"][0].astype(np.uint8).nonzero()\n      ax.scatter(x, y, z)\n      ax.set_xlim([0, 200])\n      ax.set_ylim([0, 200])\n      ax.set_zlim([0, 200])\n      ax.set_title(f\"input image, patient {i}\")\n        \n      # 3d plot of the label\n      ax = fig.add_subplot(132, projection = '3d')\n      z, x, y = val_ds[i][\"label\"][0].astype(np.uint8).nonzero()\n      ax.scatter(x, y, z)\n      ax.set_xlim([0, 200])\n      ax.set_ylim([0, 200])\n      ax.set_zlim([0, 200])\n      ax.set_title(f\"label, patient {i}\")\n\n      # 3d plot of the output\n      ax = fig.add_subplot(133, projection = '3d')\n      z, x, y = val_output[0].astype(np.uint8).nonzero()\n      ax.scatter(x, y, z)\n      ax.set_xlim([0, 200])\n      ax.set_ylim([0, 200])\n      ax.set_zlim([0, 200])\n      ax.set_title(f\"output, patient {i}\")\n        \n      # save the plots\n      plot_path = os.path.join(output_dir,\n                               f\"test patient {i}, n_train = {n_train}, max_epochs = {max_epochs}.png\")\n      plt.savefig(plot_path)\n      plt.show()\n      plt.close(fig)\n        \n  return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creation of the dataset\nHere, the dataset is created, and one horizontal slice of the image regarding one of the training set patients is plotted, together with the corresponding label.\nPlease specify:\n- number of training images (\"n_train\": int)\n- index of the patient's data to be plotted (\"plot_index\": int), in the set [0,...,n_train-1]\n- vertical (z-axis) coordinate corresponding to the slice (\"z_coordinate\": int).","metadata":{}},{"cell_type":"code","source":"n_train = 8\nn_test = 10 - n_train\nplot_index = 1\nz_coordinate = 70\n\ntrain_files, val_files = create_dataset(n_train, n_test)\ntrain_loader, val_loader, val_ds = transform(train_files, val_files)\n\nplot_patient(plot_index, z_coordinate, val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training of the U-Net\nHere, the U-Net is trained.\nPlease specify the integer value of \"max_epochs\", i.e. the number of epochs of the training phase. During each epoch, the model is trained once on all the images in the train set.","metadata":{}},{"cell_type":"code","source":"max_epochs = 5\n\nmetric_values_train, metric_values, epoch_loss_values, model, device, VAL_AMP = model_and_train(n_train,\n                                                                                                n_test,\n                                                                                                train_loader,\n                                                                                                val_loader,\n                                                                                                max_epochs,\n                                                                                                val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of the model's metrics\nHere we plot the trends regarding the loss function and the Dice metric computed on train and test sets.\nThe plots are automatically saved in the directory: /kaggle/working/output_plots.","metadata":{}},{"cell_type":"code","source":"plot_metrics(epoch_loss_values, metric_values, metric_values_train, 1, n_train, max_epochs)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"id":"LAB4zrRFABIy","outputId":"a9b53c82-820f-4bcc-aa41-c49c2c101d5b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot of the slices of some testing images\nHere, we choose to show some slices (corresponding to the z-coordinate specified by the elements of the vector \"z_axis_values\") for the patients in the test set. For each patient, we show the  input image, the corresponding label, and the output generated by the U-Net. Please note that the vector \"patients_indices\" must contain only integers in the interval [0, n_test-1], so changing the number of patients in the training set (and, consequently, in the test set) may require to modify the vector. Also note that the two vectors \"patients_indices\" and \"z_axis_values\" must have the same length.","metadata":{}},{"cell_type":"code","source":"patients_indices = (0, 0, 1, 1)\nz_axis_values = (82, 90, 30, 60)\n\nplot_test_slices(model, val_ds, VAL_AMP, patients_indices, z_axis_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3D plot of all the testing images\nWe now show the 3D images in the test set, together with their corresponding labels, and the reconstructions generated by the U-Net. The plots are automatically saved in the directory: /kaggle/working/test_3d_plots.\nRunning this cell requires some minutes.","metadata":{}},{"cell_type":"code","source":"plot_test_3d(VAL_AMP, device, model, val_ds, n_train, max_epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}
